{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import hstack\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction._stop_words import ENGLISH_STOP_WORDS\n",
    "films = pd.read_csv('films_clean.csv')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['genres', 'id', 'original_language', 'original_title', 'overview',\n",
       "       'popularity', 'production_companies', 'production_countries', 'runtime',\n",
       "       'spoken_languages', 'title', 'year', 'director', 'director_gender'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "films.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping all columns I won't need and keeping other for feature engineering\n",
    "films = films.drop(columns= ['original_title', 'original_language','production_countries', 'production_companies','runtime','spoken_languages', 'vote_average', 'vote_count', 'director'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the movies without a description. I kept them so far because they were analyzed in the EDA.\n",
    "films = films.drop(films[films['overview'] == 'No overview found.'].index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into male directed and female directed movies\n",
    "female_directed= films[films['director_gender']== 'female']\n",
    "male_directed= films[films['director_gender']== 'male']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genres              object\n",
       "id                   int64\n",
       "overview            object\n",
       "popularity         float64\n",
       "title               object\n",
       "year                 int64\n",
       "director_gender     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will vectorize the 'genres' column\n",
    "films.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comedy': 3,\n",
       " 'romance': 14,\n",
       " 'horror': 11,\n",
       " 'action': 0,\n",
       " 'adventure': 1,\n",
       " 'drama': 6,\n",
       " 'crime': 4,\n",
       " 'thriller': 16,\n",
       " 'fantasy': 8,\n",
       " 'sciencefiction': 15,\n",
       " 'history': 10,\n",
       " 'war': 18,\n",
       " 'foreign': 9,\n",
       " 'mystery': 13,\n",
       " 'family': 7,\n",
       " 'documentary': 5,\n",
       " 'western': 19,\n",
       " 'music': 12,\n",
       " 'animation': 2,\n",
       " 'tvmovie': 17}"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_vectorizer = CountVectorizer()\n",
    "genre_vectorizer.fit(films['genres'])\n",
    "male_genres = genre_vectorizer.transform(male_directed['genres']).toarray()\n",
    "female_genres = genre_vectorizer.transform(female_directed['genres']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the vocabulary to see if all genres are there/no duplicates\n",
    "genre_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adelemartin/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/adelemartin/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "male_genres = pd.DataFrame(male_genres, columns=genre_vectorizer.get_feature_names())\n",
    "female_genres = pd.DataFrame(female_genres, columns=genre_vectorizer.get_feature_names())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conducting NLP on Film Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will use the stemmer and the ENGLISH_STOP_WORDS library to get rid of insignificant words and make my \n",
    "#recommender more robust\n",
    "\n",
    "\n",
    "text = films['overview']\n",
    "text_male = male_directed['overview']\n",
    "text_female = female_directed['overview']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = EnglishStemmer()\n",
    "default_analyzer = CountVectorizer(stop_words=ENGLISH_STOP_WORDS).build_analyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_with_stemming(text):\n",
    "    unstemmed_words = default_analyzer(text)\n",
    "    return (stemmer.stem(word) for word in unstemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       An ugly duckling having undergone a remarkable...\n",
       "1       When a lawyer shows up at the vampire's doorst...\n",
       "2       Morgan Adams and her slave, William Shaw, are ...\n",
       "3       The life of the gambling paradise – Las Vegas ...\n",
       "4       Rich Mr. Dashwood dies, leaving his second wif...\n",
       "                              ...                        \n",
       "9574    The Sublet is a suspense driven psychological ...\n",
       "9575    A stranger named Silas flees from a devastatin...\n",
       "9576    Pretty, popular, and slim high-schooler Aly Sc...\n",
       "9577    Hyperactive teenager Kelly is enrolled into a ...\n",
       "9578    Yet another version of the classic epic, with ...\n",
       "Name: overview, Length: 9539, dtype: object"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of text before stemming\n",
    "text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ugli',\n",
       " 'duckl',\n",
       " 'have',\n",
       " 'undergon',\n",
       " 'remark',\n",
       " 'chang',\n",
       " 'harbor',\n",
       " 'feel',\n",
       " 'crush',\n",
       " 'carefre',\n",
       " 'playboy',\n",
       " 'busi',\n",
       " 'focus',\n",
       " 'brother',\n",
       " 'say']"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Overview of what the stemming has done\n",
    "list(analyze_with_stemming(text[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer_vectorizer = CountVectorizer(analyzer=analyze_with_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I am fitting on the films (including both genders)\n",
    "#and am transforming them seperately.\n",
    "\n",
    "vectors = stemmer_vectorizer.fit(text)\n",
    "male_vectorized = vectors.transform(text_male).todense()\n",
    "female_vectorized = vectors.transform(text_female).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = vectors.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_vectorized = pd.DataFrame(male_vectorized, columns=vocabulary)\n",
    "female_vectorized = pd.DataFrame(female_vectorized, columns=vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000th</th>\n",
       "      <th>007</th>\n",
       "      <th>01</th>\n",
       "      <th>04</th>\n",
       "      <th>07am</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>...</th>\n",
       "      <th>गल</th>\n",
       "      <th>ஆதவன</th>\n",
       "      <th>யப</th>\n",
       "      <th>ரம</th>\n",
       "      <th>ரமண</th>\n",
       "      <th>たけみかずち</th>\n",
       "      <th>ひめ</th>\n",
       "      <th>주식회사</th>\n",
       "      <th>찾기</th>\n",
       "      <th>첫사랑</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8876</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8877</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8878</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8879</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8880</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8881 rows × 25418 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      00  000  000th  007  01  04  07am  10  100  1000  ...  गल  ஆதவன  யப  ரம  \\\n",
       "0      0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "1      0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "2      0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "3      0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "4      0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "...   ..  ...    ...  ...  ..  ..   ...  ..  ...   ...  ...  ..   ...  ..  ..   \n",
       "8876   0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "8877   0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "8878   0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "8879   0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "8880   0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "\n",
       "      ரமண  たけみかずち  ひめ  주식회사  찾기  첫사랑  \n",
       "0       0       0   0     0   0    0  \n",
       "1       0       0   0     0   0    0  \n",
       "2       0       0   0     0   0    0  \n",
       "3       0       0   0     0   0    0  \n",
       "4       0       0   0     0   0    0  \n",
       "...   ...     ...  ..   ...  ..  ...  \n",
       "8876    0       0   0     0   0    0  \n",
       "8877    0       0   0     0   0    0  \n",
       "8878    0       0   0     0   0    0  \n",
       "8879    0       0   0     0   0    0  \n",
       "8880    0       0   0     0   0    0  \n",
       "\n",
       "[8881 rows x 25418 columns]"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000th</th>\n",
       "      <th>007</th>\n",
       "      <th>01</th>\n",
       "      <th>04</th>\n",
       "      <th>07am</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>...</th>\n",
       "      <th>गल</th>\n",
       "      <th>ஆதவன</th>\n",
       "      <th>யப</th>\n",
       "      <th>ரம</th>\n",
       "      <th>ரமண</th>\n",
       "      <th>たけみかずち</th>\n",
       "      <th>ひめ</th>\n",
       "      <th>주식회사</th>\n",
       "      <th>찾기</th>\n",
       "      <th>첫사랑</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>658 rows × 25418 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     00  000  000th  007  01  04  07am  10  100  1000  ...  गल  ஆதவன  யப  ரம  \\\n",
       "0     0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "1     0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "2     0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "3     0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "4     0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "..   ..  ...    ...  ...  ..  ..   ...  ..  ...   ...  ...  ..   ...  ..  ..   \n",
       "653   0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "654   0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "655   0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "656   0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "657   0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "\n",
       "     ரமண  たけみかずち  ひめ  주식회사  찾기  첫사랑  \n",
       "0      0       0   0     0   0    0  \n",
       "1      0       0   0     0   0    0  \n",
       "2      0       0   0     0   0    0  \n",
       "3      0       0   0     0   0    0  \n",
       "4      0       0   0     0   0    0  \n",
       "..   ...     ...  ..   ...  ..  ...  \n",
       "653    0       0   0     0   0    0  \n",
       "654    0       0   0     0   0    0  \n",
       "655    0       0   0     0   0    0  \n",
       "656    0       0   0     0   0    0  \n",
       "657    0       0   0     0   0    0  \n",
       "\n",
       "[658 rows x 25418 columns]"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_vectorized"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Numerical Data: Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_normalized_popularity = male_directed['popularity']\n",
    "f_normalized_popularity = female_directed['popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_normalized_popularity = m_normalized_popularity.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_normalized_popularity = f_normalized_popularity.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "m_normalized_popularity = scaler.fit_transform(m_normalized_popularity)\n",
    "f_normalized_popularity = scaler.fit_transform(f_normalized_popularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_normalized_popularity = pd.DataFrame(m_normalized_popularity)\n",
    "f_normalized_popularity = pd.DataFrame(f_normalized_popularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Numerical Data: Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_normalized_year = male_directed['year']\n",
    "f_normalized_year = female_directed['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_normalized_year = m_normalized_year.values.reshape(-1, 1)\n",
    "f_normalized_year = f_normalized_year.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "m_normalized_year = scaler.fit_transform(m_normalized_year)\n",
    "f_normalized_year = scaler.fit_transform(f_normalized_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_normalized_year = pd.DataFrame(m_normalized_year)\n",
    "f_normalized_year = pd.DataFrame(f_normalized_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.669476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.669476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.669476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.744984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.744984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>0.538656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>0.765181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>0.387640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>0.916198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>0.463148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>658 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0   -0.669476\n",
       "1   -0.669476\n",
       "2   -0.669476\n",
       "3   -0.744984\n",
       "4   -0.744984\n",
       "..        ...\n",
       "653  0.538656\n",
       "654  0.765181\n",
       "655  0.387640\n",
       "656  0.916198\n",
       "657  0.463148\n",
       "\n",
       "[658 rows x 1 columns]"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_normalized_year"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The 'l2' norm, also known as the Euclidean norm, refers to the length of a vector in a Euclidean space. \n",
    "normalizer = Normalizer(norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_genres_overview = pd.concat([male_genres*7, male_vectorized], axis=1)\n",
    "female_genres_overview = pd.concat([female_genres*7, female_vectorized], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer.fit_transform(male_genres_overview)\n",
    "normalizer.fit_transform(female_genres_overview)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate and Create Dataframes Ready for Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_directed.reset_index(drop=True, inplace=True)\n",
    "male_directed.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_movies = pd.concat([female_genres_overview, f_normalized_year], axis=1)\n",
    "male_movies = pd.concat([male_genres_overview, m_normalized_year], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adelemartin/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NearestNeighbors()"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neighbors = 5\n",
    "model = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "model.fit(female_movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adelemartin/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "distances, indices = model.kneighbors(male_movies[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.37562026, 4.47763762, 4.86643777, 4.90442975, 5.00000214]])"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[314, 652,   1, 284, 175]])"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>genres</th>\n",
       "      <th>id</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>director_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8880</th>\n",
       "      <td>9578</td>\n",
       "      <td>Action, Drama, Romance</td>\n",
       "      <td>30840</td>\n",
       "      <td>Yet another version of the classic epic, with ...</td>\n",
       "      <td>5.683753</td>\n",
       "      <td>Robin Hood</td>\n",
       "      <td>1991</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                  genres     id  \\\n",
       "8880   9578  Action, Drama, Romance  30840   \n",
       "\n",
       "                                               overview  popularity  \\\n",
       "8880  Yet another version of the classic epic, with ...    5.683753   \n",
       "\n",
       "           title  year director_gender  \n",
       "8880  Robin Hood  1991            male  "
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_directed.iloc[[8880]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>id</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>director_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>75802</td>\n",
       "      <td>A romantic comedy about the invention of the v...</td>\n",
       "      <td>14.331454</td>\n",
       "      <td>Hysteria</td>\n",
       "      <td>2011</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>72363</td>\n",
       "      <td>A love triangle between a businessman, his wif...</td>\n",
       "      <td>1.187410</td>\n",
       "      <td>I'm Staying</td>\n",
       "      <td>2003</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>4482</td>\n",
       "      <td>After learning of her husband's infidelities, ...</td>\n",
       "      <td>2.518051</td>\n",
       "      <td>French Twist</td>\n",
       "      <td>1995</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>14688</td>\n",
       "      <td>So called friends at a dinner party end up act...</td>\n",
       "      <td>2.878098</td>\n",
       "      <td>Change of Plans</td>\n",
       "      <td>2009</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>10111</td>\n",
       "      <td>A mockumentary that follows three couples as t...</td>\n",
       "      <td>1.873214</td>\n",
       "      <td>Confetti</td>\n",
       "      <td>2006</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              genres     id  \\\n",
       "314  Comedy, Romance  75802   \n",
       "652  Comedy, Romance  72363   \n",
       "1    Comedy, Romance   4482   \n",
       "284  Comedy, Romance  14688   \n",
       "175  Comedy, Romance  10111   \n",
       "\n",
       "                                              overview  popularity  \\\n",
       "314  A romantic comedy about the invention of the v...   14.331454   \n",
       "652  A love triangle between a businessman, his wif...    1.187410   \n",
       "1    After learning of her husband's infidelities, ...    2.518051   \n",
       "284  So called friends at a dinner party end up act...    2.878098   \n",
       "175  A mockumentary that follows three couples as t...    1.873214   \n",
       "\n",
       "               title  year director_gender  \n",
       "314         Hysteria  2011          female  \n",
       "652      I'm Staying  2003          female  \n",
       "1       French Twist  1995          female  \n",
       "284  Change of Plans  2009          female  \n",
       "175         Confetti  2006          female  "
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_directed.iloc[[314, 652,   1, 284, 175]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>genres</th>\n",
       "      <th>id</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>director_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8876</th>\n",
       "      <td>9574</td>\n",
       "      <td>Drama, Thriller, Mystery, Horror</td>\n",
       "      <td>365432</td>\n",
       "      <td>The Sublet is a suspense driven psychological ...</td>\n",
       "      <td>1.339355</td>\n",
       "      <td>The Sublet</td>\n",
       "      <td>2015</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8877</th>\n",
       "      <td>9575</td>\n",
       "      <td>Action, Thriller, Mystery, Horror</td>\n",
       "      <td>45527</td>\n",
       "      <td>A stranger named Silas flees from a devastatin...</td>\n",
       "      <td>1.270832</td>\n",
       "      <td>The Final Storm</td>\n",
       "      <td>2010</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8878</th>\n",
       "      <td>9576</td>\n",
       "      <td>Drama, Family, TVMovie</td>\n",
       "      <td>39562</td>\n",
       "      <td>Pretty, popular, and slim high-schooler Aly Sc...</td>\n",
       "      <td>0.767762</td>\n",
       "      <td>To Be Fat Like Me</td>\n",
       "      <td>2007</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8879</th>\n",
       "      <td>9577</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>14008</td>\n",
       "      <td>Hyperactive teenager Kelly is enrolled into a ...</td>\n",
       "      <td>4.392389</td>\n",
       "      <td>Cadet Kelly</td>\n",
       "      <td>2002</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8880</th>\n",
       "      <td>9578</td>\n",
       "      <td>Action, Drama, Romance</td>\n",
       "      <td>30840</td>\n",
       "      <td>Yet another version of the classic epic, with ...</td>\n",
       "      <td>5.683753</td>\n",
       "      <td>Robin Hood</td>\n",
       "      <td>1991</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                             genres      id  \\\n",
       "8876   9574   Drama, Thriller, Mystery, Horror  365432   \n",
       "8877   9575  Action, Thriller, Mystery, Horror   45527   \n",
       "8878   9576             Drama, Family, TVMovie   39562   \n",
       "8879   9577                             Comedy   14008   \n",
       "8880   9578             Action, Drama, Romance   30840   \n",
       "\n",
       "                                               overview  popularity  \\\n",
       "8876  The Sublet is a suspense driven psychological ...    1.339355   \n",
       "8877  A stranger named Silas flees from a devastatin...    1.270832   \n",
       "8878  Pretty, popular, and slim high-schooler Aly Sc...    0.767762   \n",
       "8879  Hyperactive teenager Kelly is enrolled into a ...    4.392389   \n",
       "8880  Yet another version of the classic epic, with ...    5.683753   \n",
       "\n",
       "                  title  year director_gender  \n",
       "8876         The Sublet  2015            male  \n",
       "8877    The Final Storm  2010            male  \n",
       "8878  To Be Fat Like Me  2007            male  \n",
       "8879        Cadet Kelly  2002            male  \n",
       "8880         Robin Hood  1991            male  "
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_directed.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Male_directed Movie Titles:\")\n",
    "#for i, row in male_directed.iterrows():\n",
    "#    print(f\"{i}: {row['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen Movie: [<1x35153 sparse matrix of type '<class 'numpy.int64'>'\n",
      " \twith 30 stored elements in Compressed Sparse Row format>\n",
      " 0.15648791403569726]\n",
      "Distance: 4.375620262071841\n",
      "Indices: [314 652   1]\n"
     ]
    }
   ],
   "source": [
    "chosen_index = int(input(\"Enter the index of the movie you want: \"))\n",
    "chosen_movie = male_data[chosen_index]\n",
    "chosen_distance = distances[0][chosen_index]\n",
    "chosen_indices = indices[0][:3]\n",
    "\n",
    "print(f\"Chosen Movie: {chosen_movie}\")\n",
    "print(f\"Distance: {chosen_distance}\")\n",
    "print(f\"Indices: {chosen_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_title_from_index(index):\n",
    "#    return male_directed[male_directed.index == index]['title'].values[0]\n",
    "#def get_index_from_title(title):\n",
    "#    return male_directed[male_directed.title == title]['index'].values[0]\n",
    "#\n",
    "#\n",
    "##input(\"Enter the title of the movie you want: \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_index_from_title('Sabrina')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_index_from_title(title):\n",
    "#    return male_directed[male_directed.title == title]['index'].values[0]\n",
    "#\n",
    "#def main():\n",
    "#    title = input(\"Enter the title: \")\n",
    "#    index = get_index_from_title(title)\n",
    "#    print(\"Index:\", index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_index_from_title(title):\n",
    "#    return male_directed[male_directed['title']== title]['index'].values[0]\n",
    "#\n",
    "#def main():\n",
    "#    title = input(\"Enter the title: \")\n",
    "#    try:\n",
    "#        index = get_index_from_title(title)\n",
    "#        print(\"Index:\", index)\n",
    "#    except IndexError:\n",
    "#        print(\"The movie does not exist in the database.\")\n",
    "#        print(\"Here are some recommended movies:\")\n",
    "#        # Assuming you have a dataframe of recommended movies called 'recommended_movies'\n",
    "#        recommended_movies = male_directed.sample(5)  # Change the number to specify how many recommendations you want\n",
    "#        print(recommended_movies[['title', 'index']])\n",
    "#\n",
    "#if __name__ == \"__main__\":\n",
    "#    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import streamlit as st\n",
    "#import pandas as pd\n",
    "#\n",
    "#def get_index_from_title(title):\n",
    "#    return male_directed[male_directed['title'] == title]['index'].values[0]\n",
    "#\n",
    "#def main():\n",
    "#    st.title(\"Movie Recommendation\")\n",
    "#    title = st.text_input(\"Enter the movie title:\")\n",
    "#    \n",
    "#    if st.button(\"Get Index\"):\n",
    "#        try:\n",
    "#            index = get_index_from_title(title)\n",
    "#            st.success(f\"The index for the movie '{title}' is {index}.\")\n",
    "#        except IndexError:\n",
    "#            st.error(\"The movie does not exist in the database.\")\n",
    "#            st.subheader(\"Recommended Movies:\")\n",
    "#            # Assuming you have a dataframe of recommended movies called 'recommended_movies'\n",
    "#            recommended_movies = male_directed.sample(5)  # Change the number to specify how many recommendations you want\n",
    "#            st.table(recommended_movies[['title', 'index']])\n",
    "#\n",
    "#if __name__ == \"__main__\":\n",
    "#    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
