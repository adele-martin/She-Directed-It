{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import hstack\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction._stop_words import ENGLISH_STOP_WORDS\n",
    "films = pd.read_csv('films_clean.csv')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['genres', 'id', 'original_language', 'original_title', 'overview',\n",
       "       'popularity', 'production_companies', 'production_countries', 'runtime',\n",
       "       'spoken_languages', 'title', 'year', 'director', 'director_gender'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "films.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping all columns I won't need and keeping other for feature engineering\n",
    "films = films.drop(columns= ['original_title', 'original_language', 'production_companies','runtime','spoken_languages', 'director'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the movies without a description. I kept them so far because they were analyzed in the EDA.\n",
    "films = films.drop(films[films['overview'] == 'No overview found.'].index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into male directed and female directed movies\n",
    "female_directed= films[films['director_gender']== 'female']\n",
    "male_directed= films[films['director_gender']== 'male']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genres                   object\n",
       "id                        int64\n",
       "overview                 object\n",
       "popularity              float64\n",
       "production_countries     object\n",
       "title                    object\n",
       "year                      int64\n",
       "director_gender          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will vectorize the 'genres' column\n",
    "films.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_vectorizer = CountVectorizer()\n",
    "genre_vectorizer.fit(films['genres'])\n",
    "male_genres = genre_vectorizer.transform(male_directed['genres']).toarray()\n",
    "female_genres = genre_vectorizer.transform(female_directed['genres']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comedy': 3,\n",
       " 'romance': 14,\n",
       " 'horror': 11,\n",
       " 'action': 0,\n",
       " 'adventure': 1,\n",
       " 'drama': 6,\n",
       " 'crime': 4,\n",
       " 'thriller': 16,\n",
       " 'fantasy': 8,\n",
       " 'sciencefiction': 15,\n",
       " 'history': 10,\n",
       " 'war': 18,\n",
       " 'foreign': 9,\n",
       " 'mystery': 13,\n",
       " 'family': 7,\n",
       " 'documentary': 5,\n",
       " 'western': 19,\n",
       " 'music': 12,\n",
       " 'animation': 2,\n",
       " 'tvmovie': 17}"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the vocabulary to see if all genres are there/no duplicates\n",
    "genre_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adelemartin/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/adelemartin/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "male_genres = pd.DataFrame(male_genres, columns=genre_vectorizer.get_feature_names())\n",
    "female_genres = pd.DataFrame(female_genres, columns=genre_vectorizer.get_feature_names())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conducting NLP on Film Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will use the stemmer and the ENGLISH_STOP_WORDS library to get rid of insignificant words and make my \n",
    "#recommender more robust\n",
    "\n",
    "\n",
    "text = films['overview']\n",
    "text_male = male_directed['overview']\n",
    "text_female = female_directed['overview']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = EnglishStemmer()\n",
    "default_analyzer = CountVectorizer(stop_words=ENGLISH_STOP_WORDS).build_analyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_with_stemming(text):\n",
    "    unstemmed_words = default_analyzer(text)\n",
    "    return (stemmer.stem(word) for word in unstemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       An ugly duckling having undergone a remarkable...\n",
       "1       When a lawyer shows up at the vampire's doorst...\n",
       "2       Morgan Adams and her slave, William Shaw, are ...\n",
       "3       The life of the gambling paradise – Las Vegas ...\n",
       "4       Rich Mr. Dashwood dies, leaving his second wif...\n",
       "                              ...                        \n",
       "9574    The Sublet is a suspense driven psychological ...\n",
       "9575    A stranger named Silas flees from a devastatin...\n",
       "9576    Pretty, popular, and slim high-schooler Aly Sc...\n",
       "9577    Hyperactive teenager Kelly is enrolled into a ...\n",
       "9578    Yet another version of the classic epic, with ...\n",
       "Name: overview, Length: 9539, dtype: object"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of text before stemming\n",
    "text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ugli',\n",
       " 'duckl',\n",
       " 'have',\n",
       " 'undergon',\n",
       " 'remark',\n",
       " 'chang',\n",
       " 'harbor',\n",
       " 'feel',\n",
       " 'crush',\n",
       " 'carefre',\n",
       " 'playboy',\n",
       " 'busi',\n",
       " 'focus',\n",
       " 'brother',\n",
       " 'say']"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Overview of what the stemming has done\n",
    "list(analyze_with_stemming(text[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer_vectorizer = CountVectorizer(analyzer=analyze_with_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I am fitting on the films (including both genders)\n",
    "#and am transforming them seperately.\n",
    "\n",
    "vectors = stemmer_vectorizer.fit(text)\n",
    "male_vectorized = vectors.transform(text_male).todense()\n",
    "female_vectorized = vectors.transform(text_female).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = vectors.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_vectorized = pd.DataFrame(male_vectorized, columns=vocabulary)\n",
    "female_vectorized = pd.DataFrame(female_vectorized, columns=vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000th</th>\n",
       "      <th>007</th>\n",
       "      <th>01</th>\n",
       "      <th>04</th>\n",
       "      <th>07am</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>...</th>\n",
       "      <th>गल</th>\n",
       "      <th>ஆதவன</th>\n",
       "      <th>யப</th>\n",
       "      <th>ரம</th>\n",
       "      <th>ரமண</th>\n",
       "      <th>たけみかずち</th>\n",
       "      <th>ひめ</th>\n",
       "      <th>주식회사</th>\n",
       "      <th>찾기</th>\n",
       "      <th>첫사랑</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8876</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8877</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8878</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8879</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8880</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8881 rows × 25418 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      00  000  000th  007  01  04  07am  10  100  1000  ...  गल  ஆதவன  யப  ரம  \\\n",
       "0      0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "1      0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "2      0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "3      0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "4      0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "...   ..  ...    ...  ...  ..  ..   ...  ..  ...   ...  ...  ..   ...  ..  ..   \n",
       "8876   0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "8877   0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "8878   0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "8879   0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "8880   0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "\n",
       "      ரமண  たけみかずち  ひめ  주식회사  찾기  첫사랑  \n",
       "0       0       0   0     0   0    0  \n",
       "1       0       0   0     0   0    0  \n",
       "2       0       0   0     0   0    0  \n",
       "3       0       0   0     0   0    0  \n",
       "4       0       0   0     0   0    0  \n",
       "...   ...     ...  ..   ...  ..  ...  \n",
       "8876    0       0   0     0   0    0  \n",
       "8877    0       0   0     0   0    0  \n",
       "8878    0       0   0     0   0    0  \n",
       "8879    0       0   0     0   0    0  \n",
       "8880    0       0   0     0   0    0  \n",
       "\n",
       "[8881 rows x 25418 columns]"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000th</th>\n",
       "      <th>007</th>\n",
       "      <th>01</th>\n",
       "      <th>04</th>\n",
       "      <th>07am</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>...</th>\n",
       "      <th>गल</th>\n",
       "      <th>ஆதவன</th>\n",
       "      <th>யப</th>\n",
       "      <th>ரம</th>\n",
       "      <th>ரமண</th>\n",
       "      <th>たけみかずち</th>\n",
       "      <th>ひめ</th>\n",
       "      <th>주식회사</th>\n",
       "      <th>찾기</th>\n",
       "      <th>첫사랑</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>658 rows × 25418 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     00  000  000th  007  01  04  07am  10  100  1000  ...  गल  ஆதவன  யப  ரம  \\\n",
       "0     0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "1     0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "2     0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "3     0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "4     0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "..   ..  ...    ...  ...  ..  ..   ...  ..  ...   ...  ...  ..   ...  ..  ..   \n",
       "653   0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "654   0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "655   0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "656   0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "657   0    0      0    0   0   0     0   0    0     0  ...   0     0   0   0   \n",
       "\n",
       "     ரமண  たけみかずち  ひめ  주식회사  찾기  첫사랑  \n",
       "0      0       0   0     0   0    0  \n",
       "1      0       0   0     0   0    0  \n",
       "2      0       0   0     0   0    0  \n",
       "3      0       0   0     0   0    0  \n",
       "4      0       0   0     0   0    0  \n",
       "..   ...     ...  ..   ...  ..  ...  \n",
       "653    0       0   0     0   0    0  \n",
       "654    0       0   0     0   0    0  \n",
       "655    0       0   0     0   0    0  \n",
       "656    0       0   0     0   0    0  \n",
       "657    0       0   0     0   0    0  \n",
       "\n",
       "[658 rows x 25418 columns]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_vectorized"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Numerical Data: Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_normalized_popularity = male_directed['popularity']\n",
    "f_normalized_popularity = female_directed['popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_normalized_popularity = m_normalized_popularity.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_normalized_popularity = f_normalized_popularity.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "m_normalized_popularity = scaler.fit_transform(m_normalized_popularity)\n",
    "f_normalized_popularity = scaler.fit_transform(f_normalized_popularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_normalized_popularity = pd.DataFrame(m_normalized_popularity)\n",
    "f_normalized_popularity = pd.DataFrame(f_normalized_popularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Numerical Data: Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_normalized_year = male_directed['year']\n",
    "f_normalized_year = female_directed['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_normalized_year = m_normalized_year.values.reshape(-1, 1)\n",
    "f_normalized_year = f_normalized_year.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "m_normalized_year = scaler.fit_transform(m_normalized_year)\n",
    "f_normalized_year = scaler.fit_transform(f_normalized_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_normalized_year = pd.DataFrame(m_normalized_year)\n",
    "f_normalized_year = pd.DataFrame(f_normalized_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.669476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.669476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.669476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.744984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.744984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>0.538656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>0.765181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>0.387640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>0.916198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>0.463148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>658 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0   -0.669476\n",
       "1   -0.669476\n",
       "2   -0.669476\n",
       "3   -0.744984\n",
       "4   -0.744984\n",
       "..        ...\n",
       "653  0.538656\n",
       "654  0.765181\n",
       "655  0.387640\n",
       "656  0.916198\n",
       "657  0.463148\n",
       "\n",
       "[658 rows x 1 columns]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_normalized_year"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The 'l2' norm, also known as the Euclidean norm, refers to the length of a vector in a Euclidean space. \n",
    "normalizer = Normalizer(norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_genres_overview = pd.concat([male_genres*5, male_vectorized], axis=1)\n",
    "female_genres_overview = pd.concat([female_genres*5, female_vectorized], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer.fit_transform(male_genres_overview)\n",
    "normalizer.fit_transform(female_genres_overview)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate and Create Dataframes Ready for Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_directed.reset_index(drop=True, inplace=True)\n",
    "male_directed.reset_index(inplace=True, drop=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_movies = pd.concat([female_genres_overview, f_normalized_year], axis=1)\n",
    "male_movies = pd.concat([male_genres_overview, m_normalized_year], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adelemartin/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NearestNeighbors()"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neighbors = 5\n",
    "model = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "model.fit(female_movies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adelemartin/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "distances, indices = model.kneighbors(male_movies[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.37562026, 4.47763762, 4.86643777, 4.90442975, 5.00000214]])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[314, 652,   1, 284, 175]])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>id</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>director_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>75802</td>\n",
       "      <td>A romantic comedy about the invention of the v...</td>\n",
       "      <td>14.331454</td>\n",
       "      <td>Germany, France, United Kingdom, Switzerland, ...</td>\n",
       "      <td>Hysteria</td>\n",
       "      <td>2011</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>72363</td>\n",
       "      <td>A love triangle between a businessman, his wif...</td>\n",
       "      <td>1.187410</td>\n",
       "      <td>France</td>\n",
       "      <td>I'm Staying</td>\n",
       "      <td>2003</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>4482</td>\n",
       "      <td>After learning of her husband's infidelities, ...</td>\n",
       "      <td>2.518051</td>\n",
       "      <td>France</td>\n",
       "      <td>French Twist</td>\n",
       "      <td>1995</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>14688</td>\n",
       "      <td>So called friends at a dinner party end up act...</td>\n",
       "      <td>2.878098</td>\n",
       "      <td>France</td>\n",
       "      <td>Change of Plans</td>\n",
       "      <td>2009</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>10111</td>\n",
       "      <td>A mockumentary that follows three couples as t...</td>\n",
       "      <td>1.873214</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Confetti</td>\n",
       "      <td>2006</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              genres     id  \\\n",
       "314  Comedy, Romance  75802   \n",
       "652  Comedy, Romance  72363   \n",
       "1    Comedy, Romance   4482   \n",
       "284  Comedy, Romance  14688   \n",
       "175  Comedy, Romance  10111   \n",
       "\n",
       "                                              overview  popularity  \\\n",
       "314  A romantic comedy about the invention of the v...   14.331454   \n",
       "652  A love triangle between a businessman, his wif...    1.187410   \n",
       "1    After learning of her husband's infidelities, ...    2.518051   \n",
       "284  So called friends at a dinner party end up act...    2.878098   \n",
       "175  A mockumentary that follows three couples as t...    1.873214   \n",
       "\n",
       "                                  production_countries            title  year  \\\n",
       "314  Germany, France, United Kingdom, Switzerland, ...         Hysteria  2011   \n",
       "652                                             France      I'm Staying  2003   \n",
       "1                                               France     French Twist  1995   \n",
       "284                                             France  Change of Plans  2009   \n",
       "175                                     United Kingdom         Confetti  2006   \n",
       "\n",
       "    director_gender  \n",
       "314          female  \n",
       "652          female  \n",
       "1            female  \n",
       "284          female  \n",
       "175          female  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_directed.iloc[[314, 652,   1, 284, 175]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Entered by User:\n",
      "Title: Robin Hood\n",
      "Overview: When soldier Robin happens upon the dying Robert of Loxley, he promises to return the man's sword to his family in Nottingham. There, he assumes Robert's identity; romances his widow, Marion; and draws the ire of the town's sheriff and King John's henchman, Godfrey.\n",
      "Genres: Action, Adventure\n",
      "Year: 2010\n",
      "Countri(es): United Kingdom, United States of America\n",
      "Popularity: 10.56812\n",
      "\n",
      "Recommended Movie:\n",
      "Title: Spies of Warsaw\n",
      "Overview: A military attaché at the French embassy is drawn into a world of abduction, betrayal and intrigue in the diplomatic salons and back alleys of Warsaw.\n",
      "Genres: Action, Drama, Adventure\n",
      "Year: 2013\n",
      "Countri(es): United Kingdom, United States of America, Poland\n",
      "Popularity: 2.224206\n",
      "\n",
      "Recommended Movie:\n",
      "Title: Goliath and the Sins of Babylon\n",
      "Overview: Goliath battles for the freedom of the Babylonian people.\n",
      "Genres: Adventure\n",
      "Year: 1963\n",
      "Countri(es): Italy\n",
      "Popularity: 0.068376\n",
      "\n",
      "Recommended Movie:\n",
      "Title: Black Beauty\n",
      "Overview: The fates of horses, and the people who own and command them, are revealed as Black Beauty narrates the circle of his life.\n",
      "Genres: Action, Drama, Adventure, Family\n",
      "Year: 1994\n",
      "Countri(es): United Kingdom, United States of America\n",
      "Popularity: 8.398845\n",
      "\n",
      "Recommended Movie:\n",
      "Title: Tomorrow\n",
      "Overview: Documentary film about global warming.\n",
      "Genres: Documentary\n",
      "Year: 2015\n",
      "Countri(es): France\n",
      "Popularity: 4.241058\n",
      "\n",
      "Recommended Movie:\n",
      "Title: 25 April\n",
      "Overview: A dramatization of the events at Gallipoli using the letters of the soldiers who were there.\n",
      "Genres: Documentary\n",
      "Year: 2015\n",
      "Countri(es): New Zealand\n",
      "Popularity: 0.139972\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adelemartin/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def get_title_and_overview_from_index(index, dataset):\n",
    "    matching_records = dataset[dataset.index == index]\n",
    "    return matching_records[['title', 'overview', 'genres', 'year', 'production_countries','popularity']]\n",
    "\n",
    "def get_index_from_title(title, dataset):\n",
    "    matching_records = dataset[dataset.title == title]\n",
    "    return matching_records.index[0]\n",
    "\n",
    "user_title = input(\"Please enter a movie: \")\n",
    "user_movie_index = get_index_from_title(user_title, male_directed)\n",
    "user_movie_details = get_title_and_overview_from_index(user_movie_index, male_directed)\n",
    "\n",
    "indices = get_index_from_title(user_title, male_directed)\n",
    "\n",
    "distances, indices = model.kneighbors(male_movies.iloc[indices:indices+1])\n",
    "recommended_records = [get_title_and_overview_from_index(index, female_directed) for index in indices[0]]\n",
    "\n",
    "print(\"Movie Entered by User:\")\n",
    "print('Title:', user_movie_details['title'].values[0])\n",
    "print(\"Overview:\", user_movie_details['overview'].values[0])\n",
    "print('Genres:', user_movie_details['genres'].values[0])\n",
    "print('Year:', user_movie_details['year'].values[0])\n",
    "print('Countri(es):', user_movie_details['production_countries'].values[0])\n",
    "print('Popularity:', user_movie_details['popularity'].values[0])\n",
    "print()\n",
    "\n",
    "for record in recommended_records:\n",
    "    print(\"Recommended Movie:\")\n",
    "    print('Title:', record['title'].values[0])\n",
    "    print(\"Overview:\", record['overview'].values[0])\n",
    "    print('Genres:', record['genres'].values[0])\n",
    "    print('Year:', record['year'].values[0])\n",
    "    print('Countri(es):', record['production_countries'].values[0])\n",
    "    print('Popularity:', record['popularity'].values[0])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
